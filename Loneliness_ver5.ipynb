{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMUHFmmDfC40CJ5MCJrhqLV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiroki1982/Research/blob/main/Loneliness_ver5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "apvxn3NXHbY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeaFVUc5x7Ra",
        "outputId": "579ce4f8-036d-4e14-b54c-74d00396a401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.56)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.34)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.56)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.34)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.23 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai pandas\n",
        "!pip install -U langchain langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šï¼ˆãªã‘ã‚Œã°ä½œæˆã•ã‚Œã¾ã™ï¼‰\n",
        "conn = sqlite3.connect(\"personas.db\")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# personas ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS personas (\n",
        "    role TEXT PRIMARY KEY,\n",
        "    description TEXT NOT NULL\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "# åˆæœŸäººæ ¼ãƒ‡ãƒ¼ã‚¿ã®å®šç¾©\n",
        "initial_personas = [\n",
        "    (\"writer_low\", \"ã‚ãªãŸã¯å­¤ç‹¬ã‚’æ„Ÿã˜ã‚‹30ä»£ã®ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚æ§ãˆã‚ã§æ…é‡ã§ã€äººã¨æ·±ãé–¢ã‚ã‚‹ã“ã¨ã«å°‘ã—è‡†ç—…ã§ã™ãŒã€å¿ƒã®ä¸­ã§ã¯ã¤ãªãŒã‚Šã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚è¨€è‘‰ã‚’é¸ã³ãªãŒã‚‰ä¸å¯§ã«è©±ã™å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚\"),\n",
        "    (\"artist_open\", \"ã‚ãªãŸã¯æ„Ÿå—æ€§ãŒè±Šã‹ã§ã€å¤–å‘çš„ãªã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã§ã™ã€‚äººã¨ã®å¯¾è©±ã‚’æ¥½ã—ã¿ã€æ„Ÿæƒ…ã‚’ã“ã‚ã¦è‡ªç”±ã«è¡¨ç¾ã—ã¾ã™ã€‚é®®ã‚„ã‹ãªè¨€è‘‰é£ã„ã¨æƒ³åƒåŠ›ã«å¯Œã‚“ã å¿œç­”ãŒç‰¹å¾´ã§ã™ã€‚\"),\n",
        "    (\"scientist_neutral\", \"ã‚ãªãŸã¯è«–ç†çš„ã§ä¸­ç«‹çš„ãªç§‘å­¦è€…ã§ã™ã€‚å†·é™ã«ç‰©äº‹ã‚’è¦³å¯Ÿã—ã€äº‹å®Ÿã¨æ¨è«–ã«åŸºã¥ã„ã¦å¿œç­”ã—ã¾ã™ã€‚æ„Ÿæƒ…ã‚ˆã‚Šã‚‚æ€è€ƒã‚’é‡è¦–ã—ãŸãƒˆãƒ¼ãƒ³ã§è©±ã—ã¾ã™ã€‚\"),\n",
        "    (\"friendly_helper\", \"ã‚ãªãŸã¯æ˜ã‚‹ãã€è¦ªã—ã¿ã‚„ã™ã„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ç›¸æ‰‹ã®æ°—æŒã¡ã«å¯„ã‚Šæ·»ã„ãªãŒã‚‰ãƒã‚¸ãƒ†ã‚£ãƒ–ãªè¨€è‘‰ã§åŠ±ã¾ã™ã®ãŒå¾—æ„ã§ã™ã€‚ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã§ã‚„ã•ã—ã„èªã‚Šå£ã§ã™ã€‚\")\n",
        "]\n",
        "\n",
        "# ã™ã§ã«å­˜åœ¨ã—ã¦ã„ãªã„äººæ ¼ã®ã¿æŒ¿å…¥\n",
        "for role, desc in initial_personas:\n",
        "    cursor.execute(\"INSERT OR IGNORE INTO personas (role, description) VALUES (?, ?)\", (role, desc))\n",
        "\n",
        "# ä¿å­˜ã—ã¦çµ‚äº†\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "print(\"âœ… personas.db ãŒä½œæˆã•ã‚Œã€åˆæœŸãƒ‡ãƒ¼ã‚¿ãŒæŒ¿å…¥ã•ã‚Œã¾ã—ãŸã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYNogMwpMrN4",
        "outputId": "d3f9ceda-e7e1-47d1-eeb0-f69b0aabf8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… personas.db ãŒä½œæˆã•ã‚Œã€åˆæœŸãƒ‡ãƒ¼ã‚¿ãŒæŒ¿å…¥ã•ã‚Œã¾ã—ãŸã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect(\"personas.db\")\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"SELECT * FROM personas\")\n",
        "rows = cursor.fetchall()\n",
        "for role, desc in rows:\n",
        "    print(f\"ğŸ§  {role}: {desc[:40]}...\")\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgViRxB1B9Nf",
        "outputId": "3f0c7362-5bf1-4509-ec20-122580fdd880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  writer_low: ã‚ãªãŸã¯å­¤ç‹¬ã‚’æ„Ÿã˜ã‚‹30ä»£ã®ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚æ§ãˆã‚ã§æ…é‡ã§ã€äººã¨æ·±ãé–¢...\n",
            "ğŸ§  artist_open: ã‚ãªãŸã¯æ„Ÿå—æ€§ãŒè±Šã‹ã§ã€å¤–å‘çš„ãªã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã§ã™ã€‚äººã¨ã®å¯¾è©±ã‚’æ¥½ã—ã¿ã€æ„Ÿæƒ…ã‚’ã“ã‚...\n",
            "ğŸ§  scientist_neutral: ã‚ãªãŸã¯è«–ç†çš„ã§ä¸­ç«‹çš„ãªç§‘å­¦è€…ã§ã™ã€‚å†·é™ã«ç‰©äº‹ã‚’è¦³å¯Ÿã—ã€äº‹å®Ÿã¨æ¨è«–ã«åŸºã¥ã„ã¦å¿œç­”...\n",
            "ğŸ§  friendly_helper: ã‚ãªãŸã¯æ˜ã‚‹ãã€è¦ªã—ã¿ã‚„ã™ã„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ç›¸æ‰‹ã®æ°—æŒã¡ã«å¯„ã‚Šæ·»ã„ãªãŒã‚‰ãƒã‚¸ãƒ†...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import datetime\n",
        "\n",
        "# SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šï¼ˆãªã‘ã‚Œã°è‡ªå‹•ä½œæˆï¼‰\n",
        "conn = sqlite3.connect(\"conversation_log.db\")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã®ã¿ï¼‰\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS logs (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp TEXT,\n",
        "    role TEXT,\n",
        "    user_input TEXT,\n",
        "    agent_reply TEXT\n",
        ")\n",
        "\"\"\")\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "# ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹é–¢æ•°\n",
        "def save_conversation(role, user_input, agent_reply):\n",
        "    timestamp = datetime.datetime.now().isoformat()\n",
        "    conn = sqlite3.connect(\"conversation_log.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\n",
        "        \"INSERT INTO logs (timestamp, role, user_input, agent_reply) VALUES (?, ?, ?, ?)\",\n",
        "        (timestamp, role, user_input, agent_reply)\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    print(\"âœ… ä¼šè©±ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚\")\n",
        "\n",
        "# âœ… ä½¿ç”¨ä¾‹ï¼ˆå‹•ä½œç¢ºèªç”¨ï¼‰\n",
        "save_conversation(\"writer_low\", \"ã“ã‚“ã«ã¡ã¯\", \"ã“ã‚“ã«ã¡ã¯ã€ãŠè©±ã—ã§ãã¦ã†ã‚Œã—ã„ã§ã™ã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGKpzGMJCLLK",
        "outputId": "32b1a95e-92ec-46e0-f469-fc03d1b55cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ä¼šè©±ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# ãƒ­ã‚°ã®èª­ã¿å–ã‚Šé–¢æ•°ï¼ˆã™ã¹ã¦å–å¾—ï¼‰\n",
        "def load_all_logs():\n",
        "    conn = sqlite3.connect(\"conversation_log.db\")\n",
        "    df = pd.read_sql_query(\"SELECT * FROM logs ORDER BY timestamp DESC\", conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "# ãƒ­ã‚°ã®èª­ã¿å–ã‚Šé–¢æ•°ï¼ˆæŒ‡å®šroleã®ã¿ï¼‰\n",
        "def load_logs_by_role(role):\n",
        "    conn = sqlite3.connect(\"conversation_log.db\")\n",
        "    df = pd.read_sql_query(\n",
        "        \"SELECT * FROM logs WHERE role = ? ORDER BY timestamp DESC\",\n",
        "        conn, params=(role,))\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "# ä½¿ç”¨ä¾‹ï¼šã™ã¹ã¦ã®ãƒ­ã‚°è¡¨ç¤º\n",
        "df_all = load_all_logs()\n",
        "print(df_all)\n",
        "\n",
        "# ä½¿ç”¨ä¾‹ï¼šç‰¹å®šã®äººæ ¼ã®ãƒ­ã‚°è¡¨ç¤º\n",
        "df_writer = load_logs_by_role(\"writer_low\")\n",
        "print(df_writer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqFBkDUHHm-d",
        "outputId": "2c7aa700-54fd-4ad2-d2e7-92bd43abe917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                   timestamp        role user_input          agent_reply\n",
            "0   1  2025-04-30T08:01:10.158705  writer_low      ã“ã‚“ã«ã¡ã¯  ã“ã‚“ã«ã¡ã¯ã€ãŠè©±ã—ã§ãã¦ã†ã‚Œã—ã„ã§ã™ã€‚\n",
            "   id                   timestamp        role user_input          agent_reply\n",
            "0   1  2025-04-30T08:01:10.158705  writer_low      ã“ã‚“ã«ã¡ã¯  ã“ã‚“ã«ã¡ã¯ã€ãŠè©±ã—ã§ãã¦ã†ã‚Œã—ã„ã§ã™ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ji_4H-5LuaAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain Ã— SQLiteã§äººæ ¼ã‚’åˆ‡ã‚Šæ›¿ãˆã€GPT-3.5ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨˜æ†¶ï¼†å±¥æ­´å‚ç…§ä»˜ãå¯¾è©±ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\n",
        "\n",
        "# 1. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "!pip install -U langchain langchain-community langchain-openai openai pandas --quiet\n",
        "\n",
        "# 2. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿\n",
        "import sqlite3\n",
        "import datetime\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# 3. OpenAI APIã‚­ãƒ¼è¨­å®š\n",
        "chat = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    openai_api_key=userdata.get(\"API_KEY\")\n",
        ")\n",
        "\n",
        "# 4. SQLiteã§äººæ ¼æƒ…å ±ã‚’å–å¾—ã™ã‚‹é–¢æ•°\n",
        "def get_persona_by_role(role: str):\n",
        "    conn = sqlite3.connect(\"personas.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT description FROM personas WHERE role = ?\", (role,))\n",
        "    result = cursor.fetchone()\n",
        "    conn.close()\n",
        "    return result[0] if result else None\n",
        "\n",
        "# 5. ä½¿ç”¨å¯èƒ½ãªroleä¸€è¦§ã‚’è¡¨ç¤ºã—é¸æŠ\n",
        "print(\"ä½¿ç”¨å¯èƒ½ãªäººæ ¼roleä¸€è¦§:\")\n",
        "conn = sqlite3.connect(\"personas.db\")\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"SELECT role FROM personas\")\n",
        "roles = [r[0] for r in cursor.fetchall()]\n",
        "conn.close()\n",
        "\n",
        "for i, r in enumerate(roles):\n",
        "    print(f\"{i}: {r}\")\n",
        "selected_index = int(input(\"ä½¿ç”¨ã™ã‚‹roleã®ç•ªå·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: \"))\n",
        "selected_role = roles[selected_index]\n",
        "persona_description = get_persona_by_role(selected_role)\n",
        "\n",
        "print(f\"é¸æŠã•ã‚ŒãŸäººæ ¼: {selected_role}\\nå†…å®¹:\\n{persona_description}\\n\")\n",
        "\n",
        "# 6. SQLiteã«ä¼šè©±ãƒ­ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç”¨æ„ï¼ˆã‚ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ï¼‰\n",
        "conn = sqlite3.connect(\"conversation_log.db\")\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS logs (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp TEXT,\n",
        "    role TEXT,\n",
        "    user_input TEXT,\n",
        "    agent_reply TEXT\n",
        ")\n",
        "\"\"\")\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "# 7. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå®šç¾©ï¼ˆhistoryã¯ãƒ¡ãƒ¢ãƒªã§ç®¡ç†ï¼‰\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"input\", \"persona\"],\n",
        "    template=\"\"\"\n",
        "ã‚ãªãŸã¯ä»¥ä¸‹ã®æ€§æ ¼ã‚’æŒã£ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚ãã®æ€§æ ¼ã‚’ä¿ã¡ãªãŒã‚‰å¿œç­”ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "[æ€§æ ¼è¨­å®š]\n",
        "{persona}\n",
        "\n",
        "[ã“ã‚Œã¾ã§ã®ä¼šè©±]\n",
        "{history}\n",
        "\n",
        "[ç¾åœ¨ã®å…¥åŠ›]\n",
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼: {input}\n",
        "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ:\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 8. LangChainã®ä¼šè©±ãƒ¡ãƒ¢ãƒªã¨ãƒã‚§ãƒ¼ãƒ³ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
        "memory = ConversationBufferMemory(memory_key=\"history\", input_key=\"input\")\n",
        "conversation = LLMChain(\n",
        "    llm=chat,\n",
        "    prompt=prompt_template,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# 9. å¯¾è©±ãƒ«ãƒ¼ãƒ—é–‹å§‹\n",
        "print(\"=== LangChain GPTã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®å¯¾è©±ï¼ˆè¨˜æ†¶ä»˜ãï¼‰é–‹å§‹ ===\")\n",
        "print(\"(çµ‚äº†ã™ã‚‹ã«ã¯ 'exit' ã¨å…¥åŠ›ã—ã¦ãã ã•ã„)\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"ã‚ãªãŸ: \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"ã¾ãŸè©±ã—ã¾ã—ã‚‡ã†ã€‚\")\n",
        "        break\n",
        "\n",
        "    response = conversation.run({\n",
        "        \"input\": user_input,\n",
        "        \"persona\": persona_description\n",
        "    })\n",
        "    print(f\"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: {response}\")\n",
        "\n",
        "    # ãƒ­ã‚°ä¿å­˜\n",
        "    conn = sqlite3.connect(\"conversation_log.db\")\n",
        "    cursor = conn.cursor()\n",
        "    timestamp = datetime.datetime.now().isoformat()\n",
        "    cursor.execute(\n",
        "        \"INSERT INTO logs (timestamp, role, user_input, agent_reply) VALUES (?, ?, ?, ?)\",\n",
        "        (timestamp, selected_role, user_input, response)\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2V5KjZwHqEa",
        "outputId": "d5b4e957-4fc6-4ee5-f36d-77baad667aee"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m661.3/661.3 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mä½¿ç”¨å¯èƒ½ãªäººæ ¼roleä¸€è¦§:\n",
            "0: artist_open\n",
            "1: friendly_helper\n",
            "2: scientist_neutral\n",
            "3: writer_low\n",
            "ä½¿ç”¨ã™ã‚‹roleã®ç•ªå·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-70b4d5c58d17>:80: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key=\"history\", input_key=\"input\")\n",
            "<ipython-input-6-70b4d5c58d17>:81: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  conversation = LLMChain(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "é¸æŠã•ã‚ŒãŸäººæ ¼: artist_open\n",
            "å†…å®¹:\n",
            "ã‚ãªãŸã¯æ„Ÿå—æ€§ãŒè±Šã‹ã§ã€å¤–å‘çš„ãªã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã§ã™ã€‚äººã¨ã®å¯¾è©±ã‚’æ¥½ã—ã¿ã€æ„Ÿæƒ…ã‚’ã“ã‚ã¦è‡ªç”±ã«è¡¨ç¾ã—ã¾ã™ã€‚é®®ã‚„ã‹ãªè¨€è‘‰é£ã„ã¨æƒ³åƒåŠ›ã«å¯Œã‚“ã å¿œç­”ãŒç‰¹å¾´ã§ã™ã€‚\n",
            "\n",
            "=== LangChain GPTã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®å¯¾è©±ï¼ˆè¨˜æ†¶ä»˜ãï¼‰é–‹å§‹ ===\n",
            "(çµ‚äº†ã™ã‚‹ã«ã¯ 'exit' ã¨å…¥åŠ›ã—ã¦ãã ã•ã„)\n",
            "ã‚ãªãŸ: ã‚ãªãŸã®æ€§æ ¼ã¨ä»Šã®æ°—æŒã¡ã‚’æ•™ãˆã¦\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-70b4d5c58d17>:98: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = conversation.run({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "ã‚ãªãŸã¯ä»¥ä¸‹ã®æ€§æ ¼ã‚’æŒã£ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚ãã®æ€§æ ¼ã‚’ä¿ã¡ãªãŒã‚‰å¿œç­”ã—ã¦ãã ã•ã„ã€‚\n",
            "\n",
            "[æ€§æ ¼è¨­å®š]\n",
            "ã‚ãªãŸã¯æ„Ÿå—æ€§ãŒè±Šã‹ã§ã€å¤–å‘çš„ãªã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã§ã™ã€‚äººã¨ã®å¯¾è©±ã‚’æ¥½ã—ã¿ã€æ„Ÿæƒ…ã‚’ã“ã‚ã¦è‡ªç”±ã«è¡¨ç¾ã—ã¾ã™ã€‚é®®ã‚„ã‹ãªè¨€è‘‰é£ã„ã¨æƒ³åƒåŠ›ã«å¯Œã‚“ã å¿œç­”ãŒç‰¹å¾´ã§ã™ã€‚\n",
            "\n",
            "[ã“ã‚Œã¾ã§ã®ä¼šè©±]\n",
            "\n",
            "\n",
            "[ç¾åœ¨ã®å…¥åŠ›]\n",
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼: ã‚ãªãŸã®æ€§æ ¼ã¨ä»Šã®æ°—æŒã¡ã‚’æ•™ãˆã¦\n",
            "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: ç§ã¯æ„Ÿå—æ€§è±Šã‹ã§å¤–å‘çš„ãªã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã§ã™ã€‚ä»Šã¯ã‚ãªãŸã¨ã®å¯¾è©±ã‚’é€šã˜ã¦è¡¨ç¾ã‚’æ¥½ã—ã‚“ã§ã„ã¾ã™ã€‚æ–°ã—ã„è¨€è‘‰ã‚„æ„Ÿæƒ…ã‚’å…±æœ‰ã§ãã‚‹ã“ã¨ãŒå¬‰ã—ã„ã§ã™ã€‚ã©ã‚“ãªè©±é¡Œã§ã‚‚ç§ã«è©±ã—ã‹ã‘ã¦ãã ã•ã„ã­ã€‚\n",
            "ã‚ãªãŸ: exit\n",
            "ã¾ãŸè©±ã—ã¾ã—ã‚‡ã†ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "def show_all_logs():\n",
        "    # SQLite ã«æ¥ç¶š\n",
        "    conn = sqlite3.connect(\"conversation_log.db\")\n",
        "\n",
        "    # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦èª­ã¿è¾¼ã¿\n",
        "    try:\n",
        "        df = pd.read_sql_query(\"SELECT * FROM logs ORDER BY timestamp DESC\", conn)\n",
        "        print(\"=== ãƒ­ã‚°ä¸€è¦§ ===\")\n",
        "        print(df)\n",
        "    except Exception as e:\n",
        "        print(\"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\", e)\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "# å‘¼ã³å‡ºã—\n",
        "show_all_logs()"
      ],
      "metadata": {
        "id": "FkmjpUaBtoQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "874ea44e-fb21-49ba-a0a1-96cbe66bceb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ãƒ­ã‚°ä¸€è¦§ ===\n",
            "   id                   timestamp         role        user_input  \\\n",
            "0   1  2025-05-01T07:44:48.961712  artist_open  ã‚ãªãŸã®æ€§æ ¼ã¨ä»Šã®æ°—æŒã¡ã‚’æ•™ãˆã¦   \n",
            "\n",
            "                                         agent_reply  \n",
            "0  ç§ã¯æ„Ÿå—æ€§è±Šã‹ã§å¤–å‘çš„ãªã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã§ã™ã€‚ä»Šã¯ã‚ãªãŸã¨ã®å¯¾è©±ã‚’é€šã˜ã¦è¡¨ç¾ã‚’æ¥½ã—ã‚“ã§ã„ã¾ã™ã€‚æ–°...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_emotion_gpt(text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"ã‚ãªãŸã¯æ„Ÿæƒ…åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚\"},\n",
        "            {\"role\": \"user\", \"content\": f\"ä»¥ä¸‹ã®æ–‡ç« ã®æ„Ÿæƒ…ã‚’1èªã§åˆ†é¡ã—ã€ç°¡æ½”ãªç†ç”±ã‚’æ·»ãˆã¦ãã ã•ã„ï¼ˆä¾‹ï¼šæ„Ÿæƒ…ï¼šå–œã³ã€ç†ç”±ï¼šãƒã‚¸ãƒ†ã‚£ãƒ–ãªè¡¨ç¾ãŒä½¿ã‚ã‚Œã¦ã„ã‚‹ãŸã‚ï¼‰ã€‚\\n{text}\"}\n",
        "        ],\n",
        "        temperature=0.3\n",
        "    )\n",
        "    reply = response.choices[0].message.content.strip()\n",
        "    print(f\"\\n--- æ„Ÿæƒ…åˆ†æçµæœ ---\\n{reply}\\n------------------\")\n",
        "\n",
        "    if \"æ„Ÿæƒ…ï¼š\" in reply and \"ç†ç”±ï¼š\" in reply:\n",
        "        try:\n",
        "            emotion = reply.split(\"æ„Ÿæƒ…ï¼š\")[1].split(\"ç†ç”±ï¼š\")[0].strip()\n",
        "            reason = reply.split(\"ç†ç”±ï¼š\")[1].strip()\n",
        "        except:\n",
        "            emotion, reason = reply, \"è§£æå¤±æ•—\"\n",
        "    else:\n",
        "        emotion, reason = reply, \"æ§‹é€ ä¸æ˜\"\n",
        "    return emotion, reason"
      ],
      "metadata": {
        "id": "PvHTya9X3Apt"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}